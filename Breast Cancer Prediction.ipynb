{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wisconsin (Diagnostic) Data Set is used to predict Breast Cancer using basic Artificial Neural Network.\n",
    "# For this, I have used Keras which is a high-level Neural Networks API built on top of low level neural networks APIs like Tensorflow and Theano.\n",
    "# As it is high-level, many things are already taken care of therefore it is easy to work with and a great tool to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "data = pd.read_csv('./data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['Unnamed: 32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 2:].values\n",
    "y = data.iloc[:, 1].values\n",
    "\n",
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "y = labelencoder_X_1.fit_transform(y)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 40)\n",
    "\n",
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fayas\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"tanh\", input_dim=30, units=16, kernel_initializer=\"glorot_uniform\")`\n",
      "  \n",
      "C:\\Users\\fayas\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.3)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim=16, init='glorot_uniform', activation='tanh', input_dim=30))\n",
    "# Adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(p=0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fayas\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"tanh\", units=16, kernel_initializer=\"glorot_uniform\")`\n",
      "  \n",
      "C:\\Users\\fayas\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.3)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim=16, init='glorot_uniform', activation='tanh'))\n",
    "# Adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(p=0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fayas\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"glorot_uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim=1, init='glorot_uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output_dim is 1 as we want only 1 output from the final layer.\n",
    "\n",
    "Sigmoid function is used when dealing with classfication problems with 2 types of results.(Softmax function is used for 3 or more classification results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fayas\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "398/398 [==============================] - 0s 460us/step - loss: 0.8829 - accuracy: 0.3668\n",
      "Epoch 2/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.7927 - accuracy: 0.4472\n",
      "Epoch 3/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.7143 - accuracy: 0.5226\n",
      "Epoch 4/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.6275 - accuracy: 0.6533\n",
      "Epoch 5/150\n",
      "398/398 [==============================] - 0s 25us/step - loss: 0.5593 - accuracy: 0.7085\n",
      "Epoch 6/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.4905 - accuracy: 0.7864\n",
      "Epoch 7/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.4377 - accuracy: 0.8241\n",
      "Epoch 8/150\n",
      "398/398 [==============================] - 0s 28us/step - loss: 0.4200 - accuracy: 0.8392\n",
      "Epoch 9/150\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.4091 - accuracy: 0.8417\n",
      "Epoch 10/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.3408 - accuracy: 0.8869\n",
      "Epoch 11/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.3314 - accuracy: 0.8819\n",
      "Epoch 12/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.3245 - accuracy: 0.8744\n",
      "Epoch 13/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.3064 - accuracy: 0.8995\n",
      "Epoch 14/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.2900 - accuracy: 0.8945\n",
      "Epoch 15/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.2721 - accuracy: 0.8945\n",
      "Epoch 16/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.2401 - accuracy: 0.9271\n",
      "Epoch 17/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.2622 - accuracy: 0.9146\n",
      "Epoch 18/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.2341 - accuracy: 0.9221\n",
      "Epoch 19/150\n",
      "398/398 [==============================] - 0s 25us/step - loss: 0.2323 - accuracy: 0.9196\n",
      "Epoch 20/150\n",
      "398/398 [==============================] - 0s 22us/step - loss: 0.2493 - accuracy: 0.9171\n",
      "Epoch 21/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.2011 - accuracy: 0.9347\n",
      "Epoch 22/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.2047 - accuracy: 0.9372\n",
      "Epoch 23/150\n",
      "398/398 [==============================] - 0s 25us/step - loss: 0.2023 - accuracy: 0.9296\n",
      "Epoch 24/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.1693 - accuracy: 0.9548\n",
      "Epoch 25/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.1853 - accuracy: 0.9472\n",
      "Epoch 26/150\n",
      "398/398 [==============================] - 0s 25us/step - loss: 0.1712 - accuracy: 0.9472\n",
      "Epoch 27/150\n",
      "398/398 [==============================] - 0s 28us/step - loss: 0.1742 - accuracy: 0.9447\n",
      "Epoch 28/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.1828 - accuracy: 0.9372\n",
      "Epoch 29/150\n",
      "398/398 [==============================] - 0s 25us/step - loss: 0.1629 - accuracy: 0.9447\n",
      "Epoch 30/150\n",
      "398/398 [==============================] - 0s 25us/step - loss: 0.1672 - accuracy: 0.9422\n",
      "Epoch 31/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.1511 - accuracy: 0.9523\n",
      "Epoch 32/150\n",
      "398/398 [==============================] - 0s 25us/step - loss: 0.1460 - accuracy: 0.9523\n",
      "Epoch 33/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.1549 - accuracy: 0.9447\n",
      "Epoch 34/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.1387 - accuracy: 0.9548\n",
      "Epoch 35/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.1507 - accuracy: 0.9573\n",
      "Epoch 36/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.1351 - accuracy: 0.9623\n",
      "Epoch 37/150\n",
      "398/398 [==============================] - 0s 25us/step - loss: 0.1367 - accuracy: 0.9648\n",
      "Epoch 38/150\n",
      "398/398 [==============================] - 0s 25us/step - loss: 0.1338 - accuracy: 0.9598\n",
      "Epoch 39/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.1291 - accuracy: 0.9573\n",
      "Epoch 40/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.1129 - accuracy: 0.9698\n",
      "Epoch 41/150\n",
      "398/398 [==============================] - 0s 25us/step - loss: 0.1294 - accuracy: 0.9548\n",
      "Epoch 42/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.1144 - accuracy: 0.9598\n",
      "Epoch 43/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.1108 - accuracy: 0.9648\n",
      "Epoch 44/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.1162 - accuracy: 0.9573\n",
      "Epoch 45/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.0962 - accuracy: 0.9724\n",
      "Epoch 46/150\n",
      "398/398 [==============================] - 0s 25us/step - loss: 0.1173 - accuracy: 0.9548\n",
      "Epoch 47/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.1047 - accuracy: 0.9698\n",
      "Epoch 48/150\n",
      "398/398 [==============================] - 0s 25us/step - loss: 0.0991 - accuracy: 0.9673\n",
      "Epoch 49/150\n",
      "398/398 [==============================] - 0s 25us/step - loss: 0.1064 - accuracy: 0.9623\n",
      "Epoch 50/150\n",
      "398/398 [==============================] - 0s 28us/step - loss: 0.1087 - accuracy: 0.9648\n",
      "Epoch 51/150\n",
      "398/398 [==============================] - 0s 30us/step - loss: 0.1044 - accuracy: 0.9749\n",
      "Epoch 52/150\n",
      "398/398 [==============================] - 0s 25us/step - loss: 0.1011 - accuracy: 0.9623\n",
      "Epoch 53/150\n",
      "398/398 [==============================] - 0s 25us/step - loss: 0.1044 - accuracy: 0.9623\n",
      "Epoch 54/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0933 - accuracy: 0.9698\n",
      "Epoch 55/150\n",
      "398/398 [==============================] - 0s 25us/step - loss: 0.0816 - accuracy: 0.9774\n",
      "Epoch 56/150\n",
      "398/398 [==============================] - 0s 25us/step - loss: 0.0905 - accuracy: 0.9698\n",
      "Epoch 57/150\n",
      "398/398 [==============================] - 0s 25us/step - loss: 0.0968 - accuracy: 0.9724\n",
      "Epoch 58/150\n",
      "398/398 [==============================] - 0s 25us/step - loss: 0.1014 - accuracy: 0.9623\n",
      "Epoch 59/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0951 - accuracy: 0.9749\n",
      "Epoch 60/150\n",
      "398/398 [==============================] - 0s 17us/step - loss: 0.0904 - accuracy: 0.9774\n",
      "Epoch 61/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.0951 - accuracy: 0.9673\n",
      "Epoch 62/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0932 - accuracy: 0.9749\n",
      "Epoch 63/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0808 - accuracy: 0.9774\n",
      "Epoch 64/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0944 - accuracy: 0.9724\n",
      "Epoch 65/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0854 - accuracy: 0.9698\n",
      "Epoch 66/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0744 - accuracy: 0.9824\n",
      "Epoch 67/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0857 - accuracy: 0.9724\n",
      "Epoch 68/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.0870 - accuracy: 0.9673\n",
      "Epoch 69/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0887 - accuracy: 0.9698\n",
      "Epoch 70/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0839 - accuracy: 0.9749\n",
      "Epoch 71/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0748 - accuracy: 0.9774\n",
      "Epoch 72/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0739 - accuracy: 0.9799\n",
      "Epoch 73/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.0752 - accuracy: 0.9774\n",
      "Epoch 74/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0804 - accuracy: 0.9799\n",
      "Epoch 75/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0780 - accuracy: 0.9799\n",
      "Epoch 76/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0734 - accuracy: 0.9799\n",
      "Epoch 77/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0729 - accuracy: 0.9724\n",
      "Epoch 78/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0874 - accuracy: 0.9673\n",
      "Epoch 79/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0665 - accuracy: 0.9799\n",
      "Epoch 80/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 0s 23us/step - loss: 0.0687 - accuracy: 0.9774\n",
      "Epoch 81/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0746 - accuracy: 0.9824\n",
      "Epoch 82/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0781 - accuracy: 0.9749\n",
      "Epoch 83/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0774 - accuracy: 0.9849\n",
      "Epoch 84/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0757 - accuracy: 0.9749\n",
      "Epoch 85/150\n",
      "398/398 [==============================] - 0s 28us/step - loss: 0.0825 - accuracy: 0.9749\n",
      "Epoch 86/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.0718 - accuracy: 0.9774\n",
      "Epoch 87/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0705 - accuracy: 0.9824\n",
      "Epoch 88/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.0781 - accuracy: 0.9749\n",
      "Epoch 89/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0751 - accuracy: 0.9774\n",
      "Epoch 90/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.0777 - accuracy: 0.9749\n",
      "Epoch 91/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.0689 - accuracy: 0.9849\n",
      "Epoch 92/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0584 - accuracy: 0.9824\n",
      "Epoch 93/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.0712 - accuracy: 0.9774\n",
      "Epoch 94/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0659 - accuracy: 0.9799\n",
      "Epoch 95/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0729 - accuracy: 0.9698\n",
      "Epoch 96/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0704 - accuracy: 0.9774\n",
      "Epoch 97/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0647 - accuracy: 0.9774\n",
      "Epoch 98/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0659 - accuracy: 0.9799\n",
      "Epoch 99/150\n",
      "398/398 [==============================] - 0s 17us/step - loss: 0.0692 - accuracy: 0.9799\n",
      "Epoch 100/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0633 - accuracy: 0.9899\n",
      "Epoch 101/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0659 - accuracy: 0.9799\n",
      "Epoch 102/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0706 - accuracy: 0.9774\n",
      "Epoch 103/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0751 - accuracy: 0.9774\n",
      "Epoch 104/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0650 - accuracy: 0.9799\n",
      "Epoch 105/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0701 - accuracy: 0.9849\n",
      "Epoch 106/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0661 - accuracy: 0.9824\n",
      "Epoch 107/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0704 - accuracy: 0.9774\n",
      "Epoch 108/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0731 - accuracy: 0.9799\n",
      "Epoch 109/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0621 - accuracy: 0.9774\n",
      "Epoch 110/150\n",
      "398/398 [==============================] - 0s 15us/step - loss: 0.0554 - accuracy: 0.9849\n",
      "Epoch 111/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0698 - accuracy: 0.9749\n",
      "Epoch 112/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0728 - accuracy: 0.9774\n",
      "Epoch 113/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0529 - accuracy: 0.9849\n",
      "Epoch 114/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0689 - accuracy: 0.9824\n",
      "Epoch 115/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0565 - accuracy: 0.9874\n",
      "Epoch 116/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0631 - accuracy: 0.9824\n",
      "Epoch 117/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0625 - accuracy: 0.9774\n",
      "Epoch 118/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.0607 - accuracy: 0.9799\n",
      "Epoch 119/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0564 - accuracy: 0.9824\n",
      "Epoch 120/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.0699 - accuracy: 0.9774\n",
      "Epoch 121/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.0641 - accuracy: 0.9774\n",
      "Epoch 122/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0663 - accuracy: 0.9849\n",
      "Epoch 123/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0515 - accuracy: 0.9849\n",
      "Epoch 124/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0553 - accuracy: 0.9824\n",
      "Epoch 125/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0520 - accuracy: 0.9824\n",
      "Epoch 126/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0602 - accuracy: 0.9849\n",
      "Epoch 127/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0597 - accuracy: 0.9824\n",
      "Epoch 128/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.0558 - accuracy: 0.9874\n",
      "Epoch 129/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0653 - accuracy: 0.9799\n",
      "Epoch 130/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0533 - accuracy: 0.9849\n",
      "Epoch 131/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0657 - accuracy: 0.9799\n",
      "Epoch 132/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0570 - accuracy: 0.9899\n",
      "Epoch 133/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0591 - accuracy: 0.9874\n",
      "Epoch 134/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0696 - accuracy: 0.9824\n",
      "Epoch 135/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0447 - accuracy: 0.9899\n",
      "Epoch 136/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0699 - accuracy: 0.9799\n",
      "Epoch 137/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0615 - accuracy: 0.9724\n",
      "Epoch 138/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0589 - accuracy: 0.9824\n",
      "Epoch 139/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.0511 - accuracy: 0.9874\n",
      "Epoch 140/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0572 - accuracy: 0.9799\n",
      "Epoch 141/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0575 - accuracy: 0.9799\n",
      "Epoch 142/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0670 - accuracy: 0.9774\n",
      "Epoch 143/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0705 - accuracy: 0.9799\n",
      "Epoch 144/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.0658 - accuracy: 0.9799\n",
      "Epoch 145/150\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.0615 - accuracy: 0.9774\n",
      "Epoch 146/150\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.0516 - accuracy: 0.9849\n",
      "Epoch 147/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0655 - accuracy: 0.9749\n",
      "Epoch 148/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0636 - accuracy: 0.9749\n",
      "Epoch 149/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0522 - accuracy: 0.9849\n",
      "Epoch 150/150\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.0589 - accuracy: 0.9799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x23550d34348>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size=100, nb_epoch=150)\n",
    "# Long scroll ahead but worth\n",
    "# The batch size and number of epochs have been set using trial and error. Still looking for more efficient ways. Open to suggestions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch size defines number of samples that going to be propagated through the network.\n",
    "\n",
    "An Epoch is a complete pass through all the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our accuracy is 97.07602339181285%\n"
     ]
    }
   ],
   "source": [
    "print(\"Our accuracy is {}%\".format(((cm[0][0] + cm[1][1])/171)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm,annot=True)\n",
    "plt.savefig('matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
